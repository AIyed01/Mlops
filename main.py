import argparse
from model_pipeline import (
    load_data,
    prepare_data,
    train_model,
    evaluate_model,
    save_model,
    load_model,
)
import joblib
import mlflow  # type: ignore
import mlflow.sklearn  # type: ignore
from fastapi import FastAPI # type: ignore
from pydantic import BaseModel  # type: ignore
import uvicorn  # type: ignore
import mlflow   # type: ignore
MLFLOW_TRACKING_URI = "http://172.17.81.48:5000"
mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)
mlflow.set_experiment("XGBoost Experiment")
from elasticsearch import Elasticsearch # type: ignore
import mlflow # type: ignore
es = Elasticsearch(["http://localhost:9200"])
ES_INDEX = "mlflow-metrics"


app = FastAPI()
from pydantic import BaseModel
from typing import List

class ModelInput(BaseModel):
    feature_vector: List[float]  # Ensure feature vector contains numeric values

import os
import psycopg2
from fastapi import FastAPI
from pydantic import BaseModel
from typing import List
import joblib
import uvicorn
import mlflow
import mlflow.sklearn
from elasticsearch import Elasticsearch

# Initialize FastAPI
app = FastAPI()

# Database connection setup
DATABASE_URL = os.getenv("DATABASE_URL", "postgresql://postgres:postgres@db:5432/predictions_db")

# Elasticsearch setup
es = Elasticsearch(["http://localhost:9200"])
ES_INDEX = "mlflow-metrics"

# Define the ModelInput Pydantic model
class ModelInput(BaseModel):
    feature_vector: List[float]  # Ensure feature vector contains numeric values

# DB connection function
def get_db_connection():
    conn = psycopg2.connect(DATABASE_URL)
    return conn

@app.get("/")
def home():
    return {"message": "FastAPI is running!"}

@app.post("/predict")
def predict(data: ModelInput):
    try:
        # Load the trained model
        model = joblib.load("trained_model.pkl")
    except FileNotFoundError:
        return {"error": "Model not found. Train it first!"}

    # Perform prediction
    prediction = model.predict([data.feature_vector])

    # Store the prediction result in the database
    conn = get_db_connection()
    cursor = conn.cursor()
    cursor.execute(
        "INSERT INTO predictions (features, prediction) VALUES (%s, %s)",
        (str(data.feature_vector), int(prediction[0]))
    )
    conn.commit()
    cursor.close()
    conn.close()

    # Log to Elasticsearch
    log_entry = {
        "prediction": int(prediction[0]),
        "features": data.feature_vector
    }
    es.index(index=ES_INDEX, body=log_entry)

    return {"prediction": int(prediction[0])}

@app.get("/")
def home():
    return {"message": "FastAPI is running!"}
@app.post("/predict")
def predict(data: ModelInput):
    import joblib
    try:
        model = joblib.load("trained_model.pkl")  # Load trained model
    except FileNotFoundError:
        return {"error": "Model not found. Train it first!"}

    # Convert input to model format
    prediction = model.predict([data.feature_vector])
    return {"prediction": int(prediction[0])}  # Convert output to integer if needed

def execute_command(
    command, train_path=None, test_path=None, model_path=None, save_path=None
):
    global X_train, X_test, y_train, y_test, scaler, label_encoders, model
    if command == "load_data":
        print("\nüîÑ Chargement des donn√©es...")
        train_data, test_data = load_data(train_path, test_path)
        print("\n‚úÖ Donn√©es charg√©es avec succ√®s")
        return train_data, test_data

    elif command == "prepare":
        print("\nüîÑ Chargement des donn√©es...")
        train_data, test_data = load_data(train_path, test_path)
        print("\n‚öôÔ∏è Pr√©paration des donn√©es...")
        X_train, X_test, y_train, y_test, scaler, label_encoders = prepare_data(
            train_data, test_data
        )
        print("\n‚úÖ Donn√©es pr√©par√©es avec succ√®s")

    elif command == "train":
        try:
            data = joblib.load("prepared_data.pkl")
            X_train = data["X_train"]
            X_test = data["X_test"]
            y_train = data["y_train"]
            y_test = data["y_test"]
            scaler = data["scaler"]
            label_encoders = data["label_encoders"]
        except FileNotFoundError:
            print(
                "\n‚ö†Ô∏è Les donn√©es pr√©par√©es n'ont pas √©t√© trouv√©es. Ex√©cutez 'prepare' d'abord."
            )
            return

        n_neighbors = 5
        print(f"\nüéØ Entra√Ænement du mod√®le avec n_neighbors={n_neighbors}...")
        model = train_model(X_train, y_train, n_neighbors)
        print("\n‚úÖ Mod√®le entra√Æn√© avec succ√®s")
        joblib.dump(model, "trained_model.pkl")
        print("\n‚úÖ Mod√®le sauvegard√© sous 'trained_model.pkl'")

    elif command == "evaluate":
        try:
            model = joblib.load("trained_model.pkl")
        except FileNotFoundError:
            print("\n‚ö†Ô∏è Le mod√®le n'a pas √©t√© trouv√©. Ex√©cutez 'train' d'abord.")
            return

        try:
            # Load prepared data
            data = joblib.load("prepared_data.pkl")
            X_test = data["X_test"]
            y_test = data["y_test"]
        except FileNotFoundError:
            print(
                "\n‚ö†Ô∏è Les donn√©es pr√©par√©es n'ont pas √©t√© trouv√©es. Ex√©cutez 'prepare' d'abord."
            )
            return

        print("\nüìä √âvaluation du mod√®le...")

        accuracy, precision, recall, f1, report = evaluate_model(model, X_test, y_test)

        print(f"\n‚úÖ Pr√©cision: {accuracy}")
        print(f"üéØ Pr√©cision: {precision}")
        print(f"üîÑ Rappel: {recall}")
        print(f"üìä F1-score: {f1}")
        print("\nüìù Classification Report:\n", report)

    elif command == "MLflow":
        try:
            model = joblib.load("trained_model.pkl")
        except FileNotFoundError:
            print("\n‚ö†Ô∏è Le mod√®le n'a pas √©t√© trouv√©. Ex√©cutez 'train' d'abord.")
            return

        try:
            data = joblib.load("prepared_data.pkl")
            X_test = data["X_test"]
            y_test = data["y_test"]
        except FileNotFoundError:
            print("\n‚ö†Ô∏è Les donn√©es pr√©par√©es n'ont pas √©t√© trouv√©es. Ex√©cutez 'prepare' d'abord.")
            return

        print("\nüìä √âvaluation du mod√®le...")

        with mlflow.start_run():  # Start an MLflow run for evaluation
            accuracy, precision, recall, f1, report = evaluate_model(model, X_test, y_test)

            print(f"\n‚úÖ Pr√©cision: {accuracy}")
            print(f"üéØ Pr√©cision: {precision}")
            print(f"üîÑ Rappel: {recall}")
            print(f"üìä F1-score: {f1}")
            print("\nüìù Classification Report:\n", report)

            # Log metrics to MLflow
            mlflow.log_param("n_neighbors", model.n_neighbors)
            mlflow.log_metric("Accuracy", accuracy)
            mlflow.log_metric("Precision", precision)
            mlflow.log_metric("Recall", recall)
            mlflow.log_metric("F1-score", f1)

            # Fix MLflow Warning: Add input example and signature
            from mlflow.models.signature import infer_signature
            import pandas as pd

            input_example = pd.DataFrame(
                X_test[:1], columns=[f"feature_{i}" for i in range(X_test.shape[1])]
            )
            signature = infer_signature(X_test, model.predict(X_test))

            mlflow.sklearn.log_model(
                model, "model", input_example=input_example, signature=signature
            )

            # --- Send Metrics to Elasticsearch ---
            log_entry = {
                "experiment": "XGBoost Experiment",
                "model": "KNN",
                "n_neighbors": model.n_neighbors,
                "metrics": {
                    "accuracy": accuracy,
                    "precision": precision,
                    "recall": recall,
                    "f1_score": f1,
                }
            }

            es.index(index=ES_INDEX, body=log_entry)  # Send data to Elasticsearch
            print("\n‚úÖ Metrics logged to Elasticsearch")


    elif command == "save":
        if save_path:
            try:
                if "model" not in globals():
                    model = joblib.load("trained_model.pkl")

                data = joblib.load("prepared_data.pkl")
                scaler = data.get("scaler")
                label_encoders = data.get("label_encoders")

                print("\nüíæ Sauvegarde du mod√®le...")
                joblib.dump(
                    {
                        "model": model,
                        "scaler": scaler,
                        "label_encoders": label_encoders,
                    },
                    save_path,
                )
                print(f"\n‚úÖ Mod√®le sauvegard√© sous {save_path}")
            except FileNotFoundError:
                print(
                    "\n‚ö†Ô∏è Impossible de sauvegarder: le mod√®le ou les donn√©es pr√©par√©es sont introuvables."
                )
        else:
            print("\n‚ö†Ô∏è Sp√©cifiez un chemin pour la sauvegarde avec --save")

    elif command == "load":
        if model_path:
            print("\nüì• Chargement du mod√®le sauvegard√©...")
            model_data = load_model(model_path)
            print("\n‚úÖ Mod√®le charg√© avec succ√®s")
        else:
            print("\n‚ö†Ô∏è Sp√©cifiez un chemin pour charger un mod√®le avec --load")

    else:
        print("\n‚ùå Commande invalide. Utilisez prepare, train, evaluate, save, load")


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(
        description="Pipeline de traitement de donn√©es et apprentissage automatique"
    )
    parser.add_argument(
        "command",
        type=str,
        help="Commande √† ex√©cuter: load_data, prepare, train, evaluate, save, load",
    )
    parser.add_argument(
        "--train", type=str, help="Chemin vers le fichier d'entra√Ænement"
    )
    parser.add_argument("--test", type=str, help="Chemin vers le fichier de test")
    parser.add_argument("--load", type=str, help="Chemin vers un mod√®le sauvegard√©")
    parser.add_argument("--save", type=str, help="Chemin pour sauvegarder le mod√®le")
    args = parser.parse_args()

    if args.command == "serve":
        uvicorn.run(app, host="0.0.0.0", port=8000)
    else:
        execute_command(
            args.command,
            train_path=args.train,
            test_path=args.test,
            model_path=args.load,
            save_path=args.save,
        )
